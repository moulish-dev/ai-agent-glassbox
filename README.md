
# ğŸ§  **GlassMind Navigator**

### **Transparent Agents. Trustworthy Decisions. Full Explainability.**

GlassMind Navigator transforms any AI agent into a **fully observable**, **auditable**, and **explainable** system.
Every decision.
Every memory update.
Every tool call.
Fully visible. Fully traceable. Fully understandable.

Built for **Track B â€“ Agent Glass Box** of the Great Agent Hackathon.

---

## ğŸ’¡ Inspiration

Modern AI agents act, remember, reason, and take actions â€” but their internal process is still a black box.
Track B asks a critical question:

> **â€œCan you build an agent you can actually understand?â€**

This challenge aligns perfectly with my ongoing work in **Artificial Human Intelligence (AHI)**, cognitive architectures, and explainable agent systems.

I wanted to build something that:

* Shows the entire reasoning flow
* Makes memory mutations fully visible
* Reveals hidden behavioral patterns
* Helps developers debug, trust, and improve agents

**GlassMind Navigator is the answer.**

---

## ğŸ§  What It Does

GlassMind Navigator makes agent cognition **transparent** and **auditable**.

### ğŸ” **Key Features**

#### **1. Full Trajectory Visualization**

See the complete reasoning chain:

* Thoughts
* Decisions
* Tool calls
* Outputs
* Next state

#### **2. Memory Timeline Analyzer**

Inspect:

* `memory_before`
* `memory_after`
  for each node.

Watch how memory evolves step by step.

#### **3. Behavior Pattern Analyzer**

Automatically discovers:

* Tool overuse
* Reasoning loops
* Node frequency
* Unnecessary steps
* Hallucination triggers

#### **4. Error Replay Mode**

Finds failure points and reconstructs exactly where reasoning went wrong.

Perfect for debugging and safety evaluations.

#### **5. Before/After Optimization**

Change a config â†’ Re-run â†’ Instantly visualize improvement in:

* Tool calls
* Step count
* Stability
* Consistency

#### **6. Real-Time LangSmith Observability**

All major nodes use `@traceable`, giving:

* Clean execution traces
* Step-level audit logs
* Reproducible trajectories

---

## ğŸ§© How We Built It

### **Architecture Overview**

```
User  
   â†“  
LangGraph-style Agent (Plan â†’ Research â†’ Answer)  
   â†“  
Trajectory Recorder  
   â†“  
Streamlit Trace Visualizer  
   â†“  
Memory Timeline Analyzer  
   â†“  
Behavior Pattern Analyzer  
   â†“  
Improvement Engine
```

### **Core Components**

| File                            | Purpose                                     |
| ------------------------------- | ------------------------------------------- |
| `backend/graph.py`              | Agent logic, plan-research-answer pipeline  |
| `backend/models.py`             | Pydantic models for structured step logging |
| `analysis/traces_loader.py`     | Save/load agent trajectories                |
| `analysis/behavior_analysis.py` | Statistical pattern analysis                |
| `frontend/app.py`               | Streamlit interactive UI                    |
| `backend/llm.py`                | Gemini/Ollama Valyu search integration      |

### **Tech Stack**

* **LangSmith** (`@traceable`) â€” observability & auditing
* **Gemini** â€” reasoning
* **Valyu DeepSearch API** â€” research tool
* **Streamlit** â€” visualization dashboard
* **Pandas** â€” behavior analysis
* **JSON traces** â€” reproducibility
* **Python** â€” glue for agent logic

---

## ğŸš§ Challenges We Ran Into

* Ollama timeouts â†’ solved by switching to Gemini
* Making every node fully serializable for LangSmith
* Streamlit import path and environment issues
* Designing memory_before / memory_after without corrupting state
* Structuring traces that remain clean, readable, and scalable
* Turning raw logs into intuitive, human-friendly visualizations

Each challenge helped refine the final solution and reinforced the importance of **robust observability** in agentic systems.

---

## ğŸ† Accomplishments Weâ€™re Proud Of

* Built end-to-end explainability from scratch
* Achieved full trajectory capture without LangGraphâ€™s built-in tools
* Created behavior analysis that reveals real agent patterns
* Integrated LangSmith successfully for complete auditability
* Built a clean, extensible foundation for any future agent
* Delivered a UI where judges can see:

  * Why a decision was made
  * What the agent remembered
  * How memory changed
  * Where a mistake happened
  * How the improvement engine enhances stability

---

## ğŸ“š What We Learned

* Observability is a **design philosophy**, not an addon
* Memory tracking is essential for debugging AI agents
* Tool usage drastically shapes agent behavior
* Small config changes can radically alter trajectories
* Explainability requires **deliberate engineering**
* Transparency is the foundation for agent trust and safety

---

## ğŸš€ Whatâ€™s Next for GlassMind Navigator

### ğŸ”® Upcoming Enhancements

* Visual DAG-based trajectory graphs
* Natural language â€œstep explanation diffsâ€
* Multi-agent execution visualization
* Automated anomaly detection
* Reinforcement learning for config optimization
* Integration with AWS Bedrock Agents & Strands SDK
* Plugin system for custom tools and memory modules

### ğŸŒ Long-Term Vision

A **universal observability dashboard** for any agent framework â€”
advancing trust, safety, and transparency for real-world agent deployments.

---

## ğŸ›  Installation & Setup

```bash
git clone <repo>
cd glassmind-navigator

pip install -r requirements.txt
streamlit run frontend/app.py
```

Ensure:

* `.env` contains API keys (Gemini, Valyu, LangSmith)
* Gemini + Valyu APIs are active
* You have traces generated via `run_once.py`

---

## â–¶ï¸ Running the Agent

To generate a trace:

```bash
python run_once.py
```

To visualize:

```bash
streamlit run frontend/app.py
```

---

